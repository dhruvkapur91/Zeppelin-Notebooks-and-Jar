{"paragraphs":[{"text":"%md\nThis is the baseline code for HelloWorldRDD","dateUpdated":"2016-12-03T01:32:28+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728725989_52822725","id":"20161203-013205_1320717161","result":{"code":"SUCCESS","type":"HTML","msg":"<p>This is the baseline code for HelloWorldRDD</p>\n"},"dateCreated":"2016-12-03T01:32:05+0000","dateStarted":"2016-12-03T01:32:28+0000","dateFinished":"2016-12-03T01:32:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:75"},{"text":"import org.apache.spark.rdd.RDD\n\nval sentenceOne = \"This is one sentence\"\nval sentenceTwo = \"This is another sentence\"\nval sentences = Seq(sentenceOne,sentenceTwo)\n\n// creating RDD : sc is already present in zepplein... :) \nval sentencesRDD = sc.parallelize(sentences)\n\nval words = sentencesRDD.flatMap(sentence => sentence.split(\" \"))\nval result = words.map(word => (word, 1)).reduceByKey((word1, word2) => word1 + word2)\n\nresult.collect().foreach(println)\n","dateUpdated":"2016-12-03T01:37:23+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728679275_-860079145","id":"20161203-013119_552043007","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.rdd.RDD\n\nsentenceOne: String = This is one sentence\n\nsentenceTwo: String = This is another sentence\n\nsentences: Seq[String] = List(This is one sentence, This is another sentence)\n\nsentencesRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[17] at parallelize at <console>:56\n\nwords: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[18] at flatMap at <console>:58\n\nresult: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[20] at reduceByKey at <console>:60\n(another,1)\n(sentence,2)\n(one,1)\n(is,2)\n(This,2)\n"},"dateCreated":"2016-12-03T01:31:19+0000","dateStarted":"2016-12-03T01:37:23+0000","dateFinished":"2016-12-03T01:37:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:76"},{"text":"%md\nWe can encapsulate above code within a method for better testing...","dateUpdated":"2016-12-03T01:36:27+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728963309_-725591053","id":"20161203-013603_787174918","result":{"code":"SUCCESS","type":"HTML","msg":"<p>We can encapsulate above code within a method for better testing&hellip;</p>\n"},"dateCreated":"2016-12-03T01:36:03+0000","dateStarted":"2016-12-03T01:36:23+0000","dateFinished":"2016-12-03T01:36:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:77"},{"text":"object WordCountRDD {\n\n  def getWordCount(sentencesRDD : RDD[String]) : RDD[(String, Int)] = {\n    val words = sentencesRDD.flatMap(sentence => sentence.split(\" \"))\n    val result: RDD[(String, Int)] = words.map(word => (word, 1)).reduceByKey((word1, word2) => word1 + word2)\n    result.collect().foreach(println)\n    return result\n  }\n}\n","dateUpdated":"2016-12-03T01:37:28+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480729009709_545496719","id":"20161203-013649_176725414","result":{"code":"SUCCESS","type":"TEXT","msg":"\ndefined object WordCountRDD\n"},"dateCreated":"2016-12-03T01:36:49+0000","dateStarted":"2016-12-03T01:37:28+0000","dateFinished":"2016-12-03T01:37:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:78"},{"text":"%md\nLets define a trait for Wrapping all our testing dependencies...","dateUpdated":"2016-12-03T01:34:55+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728873748_593774222","id":"20161203-013433_972850779","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Lets define a trait for Wrapping all our testing dependencies&hellip;</p>\n"},"dateCreated":"2016-12-03T01:34:33+0000","dateStarted":"2016-12-03T01:34:55+0000","dateFinished":"2016-12-03T01:34:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:79"},{"text":"trait TestWrapper extends org.scalatest.FunSuite with org.scalatest.Matchers with org.scalatest.BeforeAndAfterAll with org.scalatest.GivenWhenThen\n","dateUpdated":"2016-12-03T01:34:27+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728686509_-827360165","id":"20161203-013126_1046645551","result":{"code":"SUCCESS","type":"TEXT","msg":"\ndefined trait TestWrapper\n"},"dateCreated":"2016-12-03T01:31:26+0000","dateStarted":"2016-12-03T01:34:27+0000","dateFinished":"2016-12-03T01:34:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:80"},{"text":"%md\nBelow is the original test:","dateUpdated":"2016-12-03T01:35:16+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728837508_1705051639","id":"20161203-013357_826042733","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Below is the original test:</p>\n"},"dateCreated":"2016-12-03T01:33:57+0000","dateStarted":"2016-12-03T01:35:16+0000","dateFinished":"2016-12-03T01:35:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:81"},{"text":"class WordCountRDDSpec extends TestWrapper {\n    \n  import org.apache.spark.rdd.RDD\n\n  test(\"Should return empty map when there are no words\") {\n    Given(\"An empty sequence of sentences\")\n    val noSentences = Seq.empty[String]\n    val noSentencesRDD: RDD[String] = sc.parallelize(noSentences)\n\n    When(\"We do word count\")\n    val wordCount = WordCountRDD.getWordCount(noSentencesRDD)\n\n    Then(\"We expect WordCount map to be empty\")\n    wordCount.count() should be(0)\n  }\n\n}\n","dateUpdated":"2016-12-03T01:37:44+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728916829_1664407817","id":"20161203-013516_1741370351","result":{"code":"SUCCESS","type":"TEXT","msg":"\ndefined class WordCountRDDSpec\n"},"dateCreated":"2016-12-03T01:35:16+0000","dateStarted":"2016-12-03T01:37:44+0000","dateFinished":"2016-12-03T01:37:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:82"},{"text":"%md\nLets run these tests...","dateUpdated":"2016-12-03T01:38:13+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480728921509_1093071025","id":"20161203-013521_1916757887","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Lets run these tests&hellip;</p>\n"},"dateCreated":"2016-12-03T01:35:21+0000","dateStarted":"2016-12-03T01:38:13+0000","dateFinished":"2016-12-03T01:38:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:83"},{"text":"(new WordCountRDDSpec).execute()","dateUpdated":"2016-12-03T01:38:26+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480729093269_1468029348","id":"20161203-013813_454107675","result":{"code":"SUCCESS","type":"TEXT","msg":"\u001b[32mWordCountRDDSpec:\u001b[0m\n\u001b[32m- Should return empty map when there are no words\u001b[0m\n\u001b[32m  + Given An empty sequence of sentences \u001b[0m\n\u001b[32m  + When We do word count \u001b[0m\n\u001b[32m  + Then We expect WordCount map to be empty \u001b[0m\n"},"dateCreated":"2016-12-03T01:38:13+0000","dateStarted":"2016-12-03T01:38:26+0000","dateFinished":"2016-12-03T01:38:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:84"},{"text":"","dateUpdated":"2016-12-03T01:38:37+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1480729106844_60049232","id":"20161203-013826_2021754132","dateCreated":"2016-12-03T01:38:26+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:85"}],"name":"Hello World RDD","id":"2C42FKGHR","angularObjects":{"2C1FSWPV5:shared_process":[],"2C2ANMC3H:shared_process":[],"2C27C2CAW:shared_process":[],"2C1EQ4DYT:shared_process":[],"2C2D85D6Q:shared_process":[],"2BYMYHYE7:shared_process":[],"2BZJ3HWCJ:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}